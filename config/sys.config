[
 {kernel, [
    {logger_level, info},
    {logger, [
        %% Console handler for foreground modes (rebar3 shell, TUI)
        {handler, default, logger_std_h, #{
            level => info,
            formatter => {logger_formatter, #{
                template => [time, " [", level, "] ", msg, "\n"]
            }}
        }},
        %% File handler for daemon mode (stdout goes nowhere with -detached)
        {handler, file, logger_std_h, #{
            level => debug,
            config => #{
                file => "/tmp/beamclaw_daemon.log",
                max_no_bytes => 5242880,       %% 5 MB per file
                max_no_files => 3              %% keep 3 rotated files
            },
            formatter => {logger_formatter, #{
                template => [time, " [", level, "] ", msg, "\n"]
            }}
        }}
    ]}
 ]},
 {beamclaw_core, [
    {default_provider, openrouter},
    {providers, [
        {openrouter, #{api_key  => {env, "OPENROUTER_API_KEY"},
                       base_url => "https://openrouter.ai/api/v1",
                       model    => "moonshotai/kimi-k2.5"}},
        {openai, #{api_key  => {env, "OPENAI_API_KEY"},
                   base_url => "https://api.openai.com/v1",
                   model    => "gpt-4o"}}
    ]},
    {agentic_loop, #{max_tool_iterations => 10,
                     compaction_threshold => 50,
                     compaction_target    => 20,
                     stream_chunk_size    => 80,
                     memory_flush         => true,
                     auto_context         => false,
                     auto_context_limit   => 3}},
    {autonomy_level, supervised},
    {session_ttl_seconds, 3600},
    {default_agent, <<"default">>},
    {session_persistence, true},
    {session_sharing, shared},
    {session_cleanup_interval_ms, 300000},
    {skills, #{}}
 ]},
 {beamclaw_mcp, [
    {servers, []}
 ]},
 {beamclaw_gateway, [
    {http, #{port => 18800}},
    {channels, [
        {telegram, #{token => {env, "TELEGRAM_BOT_TOKEN"}, mode => long_poll,
                     dm_policy => pairing, allow_from => []}},
        {tui,      #{enabled => true}}
    ]}
 ]},
 {beamclaw_obs, []},
 {beamclaw_memory, [
    {backend, ets},
    {embedding, #{
        enabled    => true,
        model      => "text-embedding-3-small",
        base_url   => "https://api.openai.com/v1",
        api_key    => {env, "BEAMCLAW_EMBEDDING_API_KEY"},
        dimensions => 1536
    }},
    {search, #{
        vector_weight      => 0.7,
        bm25_weight        => 0.3,
        min_score          => 0.35,
        default_limit      => 6,
        chunk_size         => 400,
        chunk_overlap      => 80,
        workspace_files    => [<<"MEMORY.md">>, <<"IDENTITY.md">>, <<"USER.md">>,
                                <<"SOUL.md">>, <<"TOOLS.md">>, <<"AGENTS.md">>],
        daily_log_lookback => 7
    }}
 ]}
].
